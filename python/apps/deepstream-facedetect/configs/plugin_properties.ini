[streammux]
live-source = 1
batch-size = 4
##time out in usec, to wait after the first buffer is available
##to push the batch even if the complete batch is not formed
batched-push-timeout = 4000000
## Set muxer output width and height
width = 1920
height = 1080
##Enable to maintain aspect ratio wrt source, and allow black borders, works
##along with width, height properties
#enable-padding=0
#nvbuf-memory-type=0
## If set to TRUE, system timestamp will be attached as ntp timestamp
## If set to FALSE, ntp timestamp from rtspsrc, if available, will be attached
# attach-sys-ts-as-ntp=1

[primary-gie]
#enable=1
#gpu-id=0
config-file= facedetectir/config_infer_primary_facedetectir.txt
model-engine-file= facedetectir/resnet18_facedetectir_pruned.etlt_b1_gpu0_int8.engine
#labelfile-path=../../../../../samples/models/Primary_Detector/labels.txt
#infer-raw-output-dir=../../../../../samples/primary_detector_raw_output/
#nvbuf-memory-type=0
#interval=0
#gie-unique-id=1

[tracker]
enable=1
tracker-width = 640
tracker-height = 384
ll-lib-file = /opt/nvidia/deepstream/deepstream-5.0/lib/libnvds_mot_klt.so
#ll-config-file required for DCF/IOU only
ll-config-file = /opt/nvidia/deepstream/deepstream-5.0/samples/configs/deepstream-app/tracker_config.yml
#ll-config-file=iou_config.txt
#gpu-id=0
#enable-batch-process applicable to DCF only
enable-batch-process = 1

[tiled-display]

width = 1920
height = 1080
#gpu-id=0
#(0): nvbuf-mem-default - Default memory allocated, specific to particular platform
#(1): nvbuf-mem-cuda-pinned - Allocate Pinned/Host cuda memory, applicable for Tesla
#(2): nvbuf-mem-cuda-device - Allocate Device cuda memory, applicable for Tesla
#(3): nvbuf-mem-cuda-unified - Allocate Unified cuda memory, applicable for Tesla
#(4): nvbuf-mem-surface-array - Allocate Surface Array memory, applicable for Jetson
#nvbuf-memory-type=0

[message-converter]
msg-conv-config = configs/dsfacedetect_msgconv_config.txt
#(0): PAYLOAD_DEEPSTREAM - Deepstream schema payload
#(1): PAYLOAD_DEEPSTREAM_MINIMAL - Deepstream schema payload minimal
#(256): PAYLOAD_RESERVED - Reserved type
#(257): PAYLOAD_CUSTOM   - Custom schema payload
msg-conv-payload-type = 0
# Name of library having custom implementation.
#msg-conv-msg2p-lib=<val>
# Id of component in case only selected message to parse.
#msg-conv-comp-id=<val>

[message-broker]

proto-lib= /opt/nvidia/deepstream/deepstream-5.0/lib/libnvds_kafka_proto.so
#Provide your msg-broker-conn-str here
conn-str = my-kafka-cluster-kafka-bootstrap;9092;face
topic = face
sync = False
#Optional:
msg-broker-config = configs/cfg_kafka.txt

[encoder]
codec = H264
bitrate = 4000000

# arch 64
preset-level = 1
insert-sps-pps = 1
bufapi-version = 1

[udpsink]
host = 224.224.255.255
port = 5400
async = False
sync = 1

[rtsp-server]
port = 8554

# Configure this group to enable cloud message consumer.
[message-consumer0]
enable=0
proto-lib=/opt/nvidia/deepstream/deepstream-5.0/lib/libnvds_kafka_proto.so
conn-str=<host>;<port>
config-file=<broker config file e.g. cfg_kafka.txt>
subscribe-topic-list=<topic1>;<topic2>;<topicN>
